{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Exploratory data analysis notebook\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TS_PATH = '/home/noahg/competitive_ml/zindi/2024/special-giggle/data/Train.csv' # train time series csv\n",
    "TEST_TS_PATH = '/home/noahg/competitive_ml/zindi/2024/special-giggle/data/Test.csv' # test time series csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time series samples: \n",
      "              event_id  precipitation  label\n",
      "0  id_spictby0jfsb_X_0       0.000000      0\n",
      "1  id_spictby0jfsb_X_1       0.095438      0\n",
      "2  id_spictby0jfsb_X_2       1.949560      0\n",
      "3  id_spictby0jfsb_X_3       3.232160      0\n",
      "4  id_spictby0jfsb_X_4       0.000000      0\n",
      "5  id_spictby0jfsb_X_5      56.025400      0\n",
      "6  id_spictby0jfsb_X_6       1.097630      0\n",
      "7  id_spictby0jfsb_X_7      23.265700      0\n",
      "8  id_spictby0jfsb_X_8       2.521400      0\n",
      "9  id_spictby0jfsb_X_9       0.000000      0\n",
      "*********************************************\n",
      "Test time series samples: \n",
      "              event_id  precipitation\n",
      "0  id_j7b6sokflo4k_X_0        0.00000\n",
      "1  id_j7b6sokflo4k_X_1        3.01864\n",
      "2  id_j7b6sokflo4k_X_2        0.00000\n",
      "3  id_j7b6sokflo4k_X_3       16.61520\n",
      "4  id_j7b6sokflo4k_X_4        2.56706\n",
      "5  id_j7b6sokflo4k_X_5        0.00000\n",
      "6  id_j7b6sokflo4k_X_6        0.00000\n",
      "7  id_j7b6sokflo4k_X_7        0.00000\n",
      "8  id_j7b6sokflo4k_X_8        0.00000\n",
      "9  id_j7b6sokflo4k_X_9        0.00000\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "train_ts = pd.read_csv(TRAIN_TS_PATH)\n",
    "test_ts = pd.read_csv(TEST_TS_PATH)\n",
    "\n",
    "# print some samples of the csv data\n",
    "print(f'Train time series samples: \\n{train_ts.head(n=10)}')\n",
    "print('*'*45)\n",
    "print(f'Test time series samples: \\n{test_ts.head(n=10)}')\n",
    "print('*'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          event_id  precipitation  label  event_t\n",
      "0  id_spictby0jfsb       0.000000      0        0\n",
      "1  id_spictby0jfsb       0.095438      0        1\n",
      "2  id_spictby0jfsb       1.949560      0        2\n",
      "3  id_spictby0jfsb       3.232160      0        3\n",
      "4  id_spictby0jfsb       0.000000      0        4\n",
      "5  id_spictby0jfsb      56.025400      0        5\n",
      "6  id_spictby0jfsb       1.097630      0        6\n",
      "7  id_spictby0jfsb      23.265700      0        7\n",
      "8  id_spictby0jfsb       2.521400      0        8\n",
      "9  id_spictby0jfsb       0.000000      0        9\n",
      "          event_id  precipitation  event_t\n",
      "0  id_j7b6sokflo4k        0.00000        0\n",
      "1  id_j7b6sokflo4k        3.01864        1\n",
      "2  id_j7b6sokflo4k        0.00000        2\n",
      "3  id_j7b6sokflo4k       16.61520        3\n",
      "4  id_j7b6sokflo4k        2.56706        4\n",
      "5  id_j7b6sokflo4k        0.00000        5\n",
      "6  id_j7b6sokflo4k        0.00000        6\n",
      "7  id_j7b6sokflo4k        0.00000        7\n",
      "8  id_j7b6sokflo4k        0.00000        8\n",
      "9  id_j7b6sokflo4k        0.00000        9\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Dataset description:\n",
    "\n",
    "An imbalance dataset is provided to you with some events containing an event and some events do not contain a flood. \n",
    "Both sets of events contain randomly select 40-60 weeks prior and post flood date, to ensure the flood event date is not always the middle index.\n",
    "\n",
    "For each location the CHIRPS precipitation data has been aggregated over a 5km radius.\n",
    "Composite cloudless images of the areas of interest have been provided along with daily CHIRPS precipitation data from 1981 to 2023.\n",
    "\n",
    "Data for 2 years, 730 days was collected. Somewhere in these 730 days per location/event ID there could be a flood. \n",
    "Due to the sparsity of identified floods we have created an imbalanced dataset where there are some \n",
    "\"events\" or \"locations\" that do not have a flood in any of the 730 days.\n",
    "\n",
    "You can think of event_id_X_1 being the 01/01/2024 and event_id_X_2 being 02/01/2024 (dd/mm/yyyy). \n",
    "We have excluded the actual dates so you can not go onto GEE to determine the value and that your model \n",
    "can be applied to any 2-year time period.\n",
    "'''\n",
    "\n",
    "# let's create a new a dataframe with columns for location, day, precipitation and flood label\n",
    "train_ts['event_id'] = train_ts['event_id'].apply(lambda x: '_'.join(x.split('_')[0:2]))\n",
    "test_ts['event_id'] = test_ts['event_id'].apply(lambda x: '_'.join(x.split('_')[0:2]))\n",
    "\n",
    "train_ts['event_t'] = train_ts.groupby('event_id').cumcount()\n",
    "test_ts['event_t'] = test_ts.groupby('event_id').cumcount()\n",
    "\n",
    "print(train_ts.head(n=10))\n",
    "print(test_ts.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events labeled as floods: 318/492020 (0.0646315190439413)\n"
     ]
    }
   ],
   "source": [
    "# let's start by seeing how many events are labeled as floods\n",
    "total_events = len(train_ts)\n",
    "num_floods = len(train_ts.query('label == 1'))\n",
    "print(f'Total number of events labeled as floods: {num_floods}/{total_events} ({(num_floods/total_events)*100.0})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total locations tracked: 674\n"
     ]
    }
   ],
   "source": [
    "# under 0.5% of the data are floods, so let's see how many locations there are\n",
    "location_ids = np.unique(train_ts['event_id'])\n",
    "print(f'Total locations tracked: {len(location_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting floods for location id_05v6zjuaf300...(0/674)\n",
      "Getting floods for location id_33zbia3ufza7...(50/674)\n",
      "Getting floods for location id_6dsap350hxxn...(100/674)\n",
      "Getting floods for location id_8y98mw911jlz...(150/674)\n",
      "Getting floods for location id_bmbwxbwe99xl...(200/674)\n",
      "Getting floods for location id_e9tnifct8ze6...(250/674)\n",
      "Getting floods for location id_h11w3q9k2hbr...(300/674)\n",
      "Getting floods for location id_jev5m3ynwb96...(350/674)\n",
      "Getting floods for location id_mfuskvdk73tt...(400/674)\n",
      "Getting floods for location id_p5ubwgtzf56t...(450/674)\n",
      "Getting floods for location id_rf31s1g9mjox...(500/674)\n",
      "Getting floods for location id_towbn6cp42pw...(550/674)\n",
      "Getting floods for location id_waydwtcrhvi7...(600/674)\n",
      "Getting floods for location id_yll130iyg7fk...(650/674)\n"
     ]
    }
   ],
   "source": [
    "# let's see which locations experience a flood\n",
    "\n",
    "floods_per_location = {} # maps a location_id to the number of floods it has\n",
    "for i, location_id in enumerate(location_ids):\n",
    "    if i % 50 == 0:\n",
    "        print(f'Getting floods for location {location_id}...({i}/{len(location_ids)})')\n",
    "\n",
    "    # get all the events for the location\n",
    "    all_events = train_ts[train_ts.event_id == location_id]\n",
    "\n",
    "    # get all flood events\n",
    "    flood_events = all_events[all_events.label == 1]\n",
    "\n",
    "    floods_per_location[location_id] = len(flood_events)\n",
    "\n",
    "floods_per_location_df = pd.DataFrame.from_dict({'locations':list(floods_per_location.keys()), 'flood':list(floods_per_location.values())})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floods per location: \n",
      "         locations  flood\n",
      "0  id_05v6zjuaf300      1\n",
      "1  id_06zma02zeea7      0\n",
      "2  id_08w2po0cz63y      0\n",
      "3  id_092vetuky9ku      0\n",
      "4  id_0987b1h04r48      1\n",
      "5  id_0b8wtfxfg90r      1\n",
      "6  id_0cnfjlvz0zup      0\n",
      "7  id_0cpm4w3t78ic      1\n",
      "8  id_0ees839cilxs      0\n",
      "9  id_0f27uesmwco5      0\n",
      "Locations that experienced a flood: 318/674 (47.18100890207715)\n"
     ]
    }
   ],
   "source": [
    "# around 47% of locations experience a flood event, so a little under half\n",
    "\n",
    "print(f'Floods per location: \\n{floods_per_location_df.head(n=10)}')\n",
    "\n",
    "flood_locations = floods_per_location_df.query('flood == 1')\n",
    "print(f'Locations that experienced a flood: {len(flood_locations)}/{len(location_ids)} ({(len(flood_locations)/len(location_ids))*100.0})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting total rainfall across all locations for month of january...: 674it [00:24, 27.39it/s]\n",
      "Getting total rainfall across all locations for month of february...: 674it [00:24, 27.40it/s]\n",
      "Getting total rainfall across all locations for month of march...: 674it [00:25, 26.27it/s]\n",
      "Getting total rainfall across all locations for month of april...: 674it [00:25, 26.21it/s]\n",
      "Getting total rainfall across all locations for month of may...: 674it [00:25, 26.22it/s]\n",
      "Getting total rainfall across all locations for month of june...: 674it [00:25, 26.71it/s]\n",
      "Getting total rainfall across all locations for month of july...: 674it [00:25, 26.54it/s]\n",
      "Getting total rainfall across all locations for month of august...: 674it [00:25, 26.26it/s]\n",
      "Getting total rainfall across all locations for month of september...: 674it [00:26, 25.71it/s]\n",
      "Getting total rainfall across all locations for month of october...: 674it [00:25, 26.16it/s]\n",
      "Getting total rainfall across all locations for month of november...: 674it [00:24, 27.22it/s]\n",
      "Getting total rainfall across all locations for month of december...: 674it [00:24, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month   y1_rainfall    y2_rainfall\n",
      "0     january  62941.128669  108286.462992\n",
      "1    february  45450.975668  101887.085405\n",
      "2       march  97384.593265   79513.842440\n",
      "3       april  24676.744120   79396.856260\n",
      "4         may  31164.324919   81300.158120\n",
      "5        june  24603.930080    9298.526242\n",
      "6        july  25217.929050   25730.747935\n",
      "7      august   3436.868888     826.290300\n",
      "8   september  16316.867483   31296.658214\n",
      "9     october   4606.646977   23589.191200\n",
      "10   november  60226.732580   35400.932686\n",
      "11   december  35320.808038   89057.679744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We have 2 years of data for each location, where event_t=0 means 01/01/yy, event_t=1 means 01/02/yy, and so on\n",
    "Where dates are in dd/mm/yy format\n",
    "Since there's 730 days per location, we can safely assume no leap years (I think - otherwise there'd be 731 days)\n",
    "'''\n",
    "\n",
    "# let's see how much rain each month had during its 2-year window across all locations\n",
    "MONTHS = {\n",
    "    'january':{'y1_start':0, 'y1_end':30, 'y2_start':365, 'y2_end':395},\n",
    "    'february':{'y1_start':31, 'y1_end':58, 'y2_start':396, 'y2_end':423},\n",
    "    'march':{'y1_start':59, 'y1_end':89, 'y2_start':424, 'y2_end':454},\n",
    "    'april':{'y1_start':90, 'y1_end':119, 'y2_start':455, 'y2_end':484},\n",
    "    'may':{'y1_start':120, 'y1_end':150, 'y2_start':485, 'y2_end':515},\n",
    "    'june':{'y1_start':151, 'y1_end':180, 'y2_start':516, 'y2_end':545},\n",
    "    'july':{'y1_start':181, 'y1_end':211, 'y2_start':546, 'y2_end':576},\n",
    "    'august':{'y1_start':212, 'y1_end':242, 'y2_start':577, 'y2_end':607},\n",
    "    'september':{'y1_start':243, 'y1_end':272, 'y2_start':608, 'y2_end':637},\n",
    "    'october':{'y1_start':273, 'y1_end':303, 'y2_start':638, 'y2_end':668},\n",
    "    'november':{'y1_start':304, 'y1_end':333, 'y2_start':669, 'y2_end':698},\n",
    "    'december':{'y1_start':334, 'y1_end':364, 'y2_start':699, 'y2_end':729}\n",
    "    }\n",
    "\n",
    "rainfall_per_month = {\n",
    "    'month': [month for month in MONTHS], \n",
    "    'y1_rainfall':[0.0 for _ in range(len(MONTHS))], \n",
    "    'y2_rainfall':[0.0 for _ in range(len(MONTHS))],\n",
    "    }\n",
    "for i, month in enumerate(MONTHS):\n",
    "    desc = f'Getting total rainfall across all locations for month of {month}...'\n",
    "    for j, location in tqdm(enumerate(location_ids), desc=desc):\n",
    "        y1_stmt = f'event_id == \"{location_id}\" & event_t >= {MONTHS[month]['y1_start']} & event_t <= {MONTHS[month]['y1_end']}'\n",
    "        y2_stmt = f'event_id == \"{location_id}\" & event_t >= {MONTHS[month]['y2_start']} & event_t <= {MONTHS[month]['y2_end']}'\n",
    "\n",
    "        # get all events for the location during month of y1\n",
    "        y1_events = train_ts.query(y1_stmt)\n",
    "\n",
    "        # get all events for the location during month of y2\n",
    "        y2_events = train_ts.query(y2_stmt)\n",
    "\n",
    "        # calculate total rainfall for location during month of y1\n",
    "        rainfall_per_month['y1_rainfall'][i] += y1_events.precipitation.sum()\n",
    "\n",
    "        # calculate total rainfall for location during month of y2\n",
    "        rainfall_per_month['y2_rainfall'][i] += y2_events.precipitation.sum()\n",
    "\n",
    "rainfall_per_month_df = pd.DataFrame.from_dict(rainfall_per_month)\n",
    "print(rainfall_per_month_df)\n",
    "rainfall_per_month_df.to_csv('rainfall_per_month.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see which months had the most rainfall for y1 and y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see which months have the most flood events across all locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see which locations experience the most rainfall across all months for y1 and y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how much rain each location gets for each month throughout y1 and y2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi-flood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
